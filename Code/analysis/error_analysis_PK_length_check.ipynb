{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking Fig1 plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import bender_class\n",
    "from config import path_to_repository\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "seaborn.set(font='Arial',context='talk',font_scale=1.0, style='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fig 1E -- min angle for 100% accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the curve fit type, 1 for linear, 2 for quadratic.  \n",
    "degree = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:/Users/toppe/OneDrive - CSU Maritime Academy/Documents/GitHub/Strain-Sensor-\\\\CSV Data/5_12_25/1.5_static_v2_velcro_5_12_25.csv']\n",
      "ADC normalized bw 0-1. ADC max:  1.0 ADC min:  0.0\n",
      "['C:/Users/toppe/OneDrive - CSU Maritime Academy/Documents/GitHub/Strain-Sensor-\\\\CSV Data/5_12_25/1.7_static_v1_velcro_5_12_25.csv']\n",
      "ADC normalized bw 0-1. ADC max:  1.0 ADC min:  0.0\n",
      "['C:/Users/toppe/OneDrive - CSU Maritime Academy/Documents/GitHub/Strain-Sensor-\\\\CSV Data/5_12_25/1.76_static_v2_velcro_5_12_25.csv']\n",
      "ADC normalized bw 0-1. ADC max:  1.0 ADC min:  0.0\n",
      "['C:/Users/toppe/OneDrive - CSU Maritime Academy/Documents/GitHub/Strain-Sensor-\\\\CSV Data/5_12_25/1.73_static_v3_velcro_5_12_25.csv']\n",
      "ADC normalized bw 0-1. ADC max:  1.0 ADC min:  0.0\n",
      "['C:/Users/toppe/OneDrive - CSU Maritime Academy/Documents/GitHub/Strain-Sensor-\\\\CSV Data/5_7_25/1.765_static_v1_velcro_5_7_25.csv']\n",
      "ADC normalized bw 0-1. ADC max:  1.0 ADC min:  0.0\n",
      "['C:/Users/toppe/OneDrive - CSU Maritime Academy/Documents/GitHub/Strain-Sensor-\\\\CSV Data/5_7_25/1.8_static_v1_velcro_5_7_25.csv']\n",
      "ADC normalized bw 0-1. ADC max:  1.0 ADC min:  0.0\n",
      "['C:/Users/toppe/OneDrive - CSU Maritime Academy/Documents/GitHub/Strain-Sensor-\\\\CSV Data/4_22_25/1.86_static_v1_4_22_25.csv']\n",
      "ADC normalized bw 0-1. ADC max:  1.0 ADC min:  0.0\n",
      "['C:/Users/toppe/OneDrive - CSU Maritime Academy/Documents/GitHub/Strain-Sensor-\\\\CSV Data/5_7_25/1.89_static_v2_velcro_5_7_25.csv']\n",
      "ADC normalized bw 0-1. ADC max:  1.0 ADC min:  0.0\n",
      "['C:/Users/toppe/OneDrive - CSU Maritime Academy/Documents/GitHub/Strain-Sensor-\\\\CSV Data/5_7_25/1.98_static_v2_velcro_5_7_25.csv']\n",
      "ADC normalized bw 0-1. ADC max:  1.0 ADC min:  0.0\n",
      "['C:/Users/toppe/OneDrive - CSU Maritime Academy/Documents/GitHub/Strain-Sensor-\\\\CSV Data/5_7_25/1.987_static_v1_velcro_5_7_25.csv']\n",
      "ADC normalized bw 0-1. ADC max:  1.0 ADC min:  0.0\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toppe\\OneDrive - CSU Maritime Academy\\Documents\\GitHub\\Strain-Sensor-\\Code\\analysis\\analysis.py:1751: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  ax[0].set_ylabel('$\\Delta R/R_o$')\n",
      "C:\\Users\\toppe\\OneDrive - CSU Maritime Academy\\Documents\\GitHub\\Strain-Sensor-\\Code\\analysis\\analysis.py:1758: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  ax[1].set_ylabel('$\\Delta R/R_o$')\n",
      "C:\\Users\\toppe\\OneDrive - CSU Maritime Academy\\Documents\\GitHub\\Strain-Sensor-\\Code\\analysis\\analysis.py:2047: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  ax1.set_ylabel('$\\Delta R/R_o$', color='b')\n",
      "C:\\Users\\toppe\\OneDrive - CSU Maritime Academy\\Documents\\GitHub\\Strain-Sensor-\\Code\\analysis\\analysis.py:2062: SyntaxWarning: invalid escape sequence '\\e'\n",
      "  ax2.set_xlabel('$\\epsilon$ (strain)')\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No CSV files found in the specified path: C:/Users/toppe/OneDrive - CSU Maritime Academy/Documents/GitHub/Strain-Sensor-\\CSV Data/6_2_25/2.1_static_v4_silpoxy_0.04_6_2_25.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 61\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_d, datafiles \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(group):\n\u001b[0;32m     60\u001b[0m     g \u001b[38;5;241m=\u001b[39m bender_class()\n\u001b[1;32m---> 61\u001b[0m     g\u001b[38;5;241m.\u001b[39mload_data(datafiles)\n\u001b[0;32m     62\u001b[0m     g\u001b[38;5;241m.\u001b[39mnormalize_adc_bw_01()\n\u001b[0;32m     63\u001b[0m     g\u001b[38;5;241m.\u001b[39mtrain_model_test_accuracy(degree\u001b[38;5;241m=\u001b[39mdegree)\n",
      "File \u001b[1;32m~\\OneDrive - CSU Maritime Academy\\Documents\\GitHub\\Strain-Sensor-\\Code\\analysis\\analysis.py:546\u001b[0m, in \u001b[0;36mbender_class.load_data\u001b[1;34m(self, regex_path)\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;66;03m# Check that csv_files is not empty\u001b[39;00m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m csv_files:\n\u001b[1;32m--> 546\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo CSV files found in the specified path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregex_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    548\u001b[0m \u001b[38;5;66;03m# Load all the data\u001b[39;00m\n\u001b[0;32m    549\u001b[0m dataframes \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No CSV files found in the specified path: C:/Users/toppe/OneDrive - CSU Maritime Academy/Documents/GitHub/Strain-Sensor-\\CSV Data/6_2_25/2.1_static_v4_silpoxy_0.04_6_2_25.csv"
     ]
    }
   ],
   "source": [
    "# 1.5 in samples\n",
    "#DS25 = os.path.join(path_to_repository , \"CSV Data/11_27_24/1_53_bubble/Bending_data_abs_1p53_11_27_24_0deg_reapply_2.csv\")\n",
    "DS25 = os.path.join(path_to_repository , \"CSV Data/5_12_25/1.5_static_v2_velcro_5_12_25.csv\")\n",
    "\n",
    "# 1.7 in samples \n",
    "#DS7_datafiles = os.path.join(path_to_repository , \"CSV Data/2_4_25/second test/Bending_data_abs_1p7_abs_1p7_2nd_reapply_2_4_25.csv\")\n",
    "DS7_datafiles = os.path.join(path_to_repository , \"CSV Data/5_12_25/1.7_static_v1_velcro_5_12_25.csv\")\n",
    "#DS8_datafiles = os.path.join(path_to_repository , \"CSV Data/4_11_25/1.787_static_vs2_v1_4_11_25.csv\")\n",
    "DS8_datafiles = os.path.join(path_to_repository , \"CSV Data/5_12_25/1.76_static_v2_velcro_5_12_25.csv\")\n",
    "#DS13_datafiles = os.path.join(path_to_repository , \"CSV Data/3_18_25/Bending_data_abs_1p732_0deg_retest_v3_3_18_25.csv\")\n",
    "DS13_datafiles = os.path.join(path_to_repository , \"CSV Data/5_12_25/1.73_static_v3_velcro_5_12_25.csv\")\n",
    "#DS14_datafiles = os.path.join(path_to_repository , \"CSV Data/3_20_25/Bending_data_abs_1p758_retest_v8_3_20_25.csv\")\n",
    "DS14_datafiles = os.path.join(path_to_repository , \"CSV Data/5_7_25/1.765_static_v1_velcro_5_7_25.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1.8 in samples\n",
    "DS3_datafiles = os.path.join(path_to_repository , \"CSV Data/5_7_25/1.8_static_v1_velcro_5_7_25.csv\")\n",
    "#DS3_datafiles = os.path.join(path_to_repository , \"CSV Data/4_15_25/1.85_static_v2_4_15_25.csv\")\n",
    "#DS4_datafiles = os.path.join(path_to_repository , \"CSV Data/4_11_25/1.86_static_vs3_v1_4_11_25.csv\")\n",
    "DS4_datafiles = os.path.join(path_to_repository , \"CSV Data/4_22_25/1.86_static_v1_4_22_25.csv\")\n",
    "#DS6_datafiles = os.path.join(path_to_repository , \"CSV Data/12_9_24/fourth/Bending_data_abs_1p897_s4_12_9_24.csv\")\n",
    "DS6_datafiles = os.path.join(path_to_repository , \"CSV Data/5_7_25/1.89_static_v2_velcro_5_7_25.csv\")\n",
    "\n",
    "\n",
    "# 1.987 in samples\n",
    "DS16_datafiles = os.path.join(path_to_repository , \"CSV Data/5_7_25/1.98_static_v2_velcro_5_7_25.csv\")\n",
    "#DS11_datafiles = os.path.join(path_to_repository , \"CSV Data/4_15_25/1.98_static_v2_4_15_25.csv\")\n",
    "DS11_datafiles = os.path.join(path_to_repository , \"CSV Data/5_7_25/1.987_static_v1_velcro_5_7_25.csv\")\n",
    "DStest = os.path.join(path_to_repository , \"CSV Data/6_2_25/2.1_static_v4_silpoxy_0.04_6_2_25.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# 2.3 in samples\n",
    "\n",
    "#DS1_datafiles = os.path.join(path_to_repository , \"CSV Data/4_15_25/2.2_static_v3_4_15_25.csv\")\n",
    "#DS2_datafiles = os.path.join(path_to_repository , \"CSV Data/4_17_25/2.24_static_v1_4_17_25.csv\")\n",
    "DS1_datafiles = os.path.join(path_to_repository , \"CSV Data/4_17_25/2.24_reapplication_v3_4_17_25.csv\")\n",
    "DS2_datafiles = os.path.join(path_to_repository , \"CSV Data/4_18_25/2.27_reapplication_v2_4_18_25.csv\")\n",
    "DS15_datafiles = os.path.join(path_to_repository , \"CSV Data/4_18_25/2.34_static_v1_4_18_25.csv\")\n",
    "\n",
    "# Added these files to PK_data_accuracy_check tab in data_25_01_14.xlsx file \n",
    "DS_all = [[DS25], \n",
    "          [DS7_datafiles, DS8_datafiles, DS13_datafiles, DS14_datafiles],\n",
    "          [DS3_datafiles, DS4_datafiles, DS6_datafiles],\n",
    "          [DS16_datafiles, DS11_datafiles, DStest],\n",
    "          [DS1_datafiles, DS2_datafiles, DS15_datafiles] \n",
    "         ]\n",
    "\n",
    "bar_labels = [\"1.5 in\", \"1.7 in\", \"1.8 in\", \"2.0 in\", \"2.3 in\"]\n",
    "bar_colors = [\"b\"]*len(bar_labels)\n",
    "ma_100_list = []\n",
    "\n",
    "# For each dataset -- show training and testing on individual datasets\n",
    "for i_g, group in enumerate(DS_all):\n",
    "    \n",
    "    ma_100_list_group = []; \n",
    "    for i_d, datafiles in enumerate(group):\n",
    "        g = bender_class()\n",
    "        g.load_data(datafiles)\n",
    "        g.normalize_adc_bw_01()\n",
    "        g.train_model_test_accuracy(degree=degree)\n",
    "        min_angle_100, all_min_angle_100 = g.get_min_accuracy_100()\n",
    "        ma_100_list_group.append(all_min_angle_100)\n",
    "    ma_100_list.append(ma_100_list_group)\n",
    "        \n",
    "g.plot_bar_chart(ma_100_list, bar_labels, title=\"Min Angle for 100% Accuracy\", ylabel=\"Min Angle (deg)\", colors=bar_colors,\n",
    "                ylim=(0, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fig 1G -- boxplot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_data_dict = {}  # Dictionary for box plot: {sample_name: error_values}\n",
    "group_dict = {}  # Dictionary to map samples to groups\n",
    "\n",
    "for i, group in enumerate(DS_all):  # Loop over groups\n",
    "    for j, datafiles in enumerate(group):  # Loop over datasets in each group\n",
    "        g = bender_class()\n",
    "        g.load_data(datafiles)\n",
    "        g.normalize_adc_bw_01()\n",
    "        #g.normalize_adc_over_R0()\n",
    "        g.train_model_test_accuracy(degree=degree)\n",
    "        \n",
    "        # Use cross_validation_angular_error to get error data\n",
    "        mean_error, std_error, predictions_df = g.cross_validation_angular_error(degree=degree)\n",
    "\n",
    "        if not isinstance(predictions_df, pd.DataFrame):\n",
    "            raise TypeError(f\"Expected cross_validation_angular_error to return a DataFrame, got {type(predictions_df)}\")\n",
    "\n",
    "        # Ensure the DataFrame contains the 'Absolute Error' column\n",
    "        if \"Absolute Error\" not in predictions_df.columns:\n",
    "            raise ValueError(f\"Dataset from {datafiles} does not contain 'Absolute Error' column\")\n",
    "\n",
    "        # Assign unique sample names and store error values\n",
    "        sample_name = f\"Group{i+1}_Sample{j+1}\"  \n",
    "        error_data_dict[sample_name] = predictions_df['Absolute Error'].tolist()\n",
    "        group_dict[sample_name] = bar_labels[i]  # Assign to group\n",
    "\n",
    "    \n",
    "g.plot_box_plot(error_data_dict, group_dict, bar_colors, bar_labels,  box_alpha=0.15, data_alpha=0.04, jitter=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pairwise plots 1F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize results list\n",
    "DS_flat = []; xlabel_flat = []\n",
    "for _, (ds_group, ds_lab) in enumerate(zip(DS_all, bar_labels)):\n",
    "    xlabel_flat.extend([ds_lab]*len(ds_group))\n",
    "    DS_flat.extend(ds_group)\n",
    "\n",
    "pairwise_min_accuracy = np.zeros((len(DS_flat), len(DS_flat))) + np.nan\n",
    "pairwise_abs_error = np.zeros((len(DS_flat), len(DS_flat))) + np.nan\n",
    "\n",
    "# Iterate over each dataset as the training dataset\n",
    "for i, train_datafiles in enumerate(DS_flat):\n",
    "    train_name = 'DS'+str(i+1)\n",
    "    \n",
    "    g = bender_class()\n",
    "    g.load_data(train_datafiles)\n",
    "    g.normalize_adc_bw_01()\n",
    "    #g.normalize_adc_over_R0()\n",
    "\n",
    "    # Train the model before testing (for off-diagonal cases)\n",
    "    # This is a model fit on training data (make this as high as possible)\n",
    "    # Just need 1 iteration to get the model\n",
    "    g.train_model_test_accuracy(perc_train = 0.99, niter=1, degree=degree)\n",
    "\n",
    "\n",
    "    for j, test_datafiles in enumerate(DS_flat):\n",
    "        \n",
    "        # Diagonal Case (Within-Sample Testing)\n",
    "        if i == j:\n",
    "            # Make a new bender class with new model (fit on 80%, test on 20% x 10 times)\n",
    "            g2 = bender_class()\n",
    "            g2.load_data(train_datafiles)\n",
    "            g2.normalize_adc_bw_01()\n",
    "            #g2.normalize_adc_over_R0()\n",
    "\n",
    "            # Do typical train on 80%, test on 20% x 10 times \n",
    "            g2.train_model_test_accuracy(perc_train = 0.8, niter=10, degree=2)\n",
    "            min_angle_100, all_min_angle_100 = g.get_min_accuracy_100()\n",
    "            pairwise_min_accuracy[i, j] = np.mean(np.array(all_min_angle_100))\n",
    "            pairwise_abs_error[i, j] = np.mean(np.hstack((g2.abs_angular_error)))\n",
    "        # Off-Diagonal Case (Cross-Sample Testing)\n",
    "        else:\n",
    "\n",
    "            # Load test dataset separately\n",
    "            g_test = bender_class()\n",
    "            g_test.load_data(test_datafiles)  \n",
    "            g_test.normalize_adc_bw_01()\n",
    "            #g_test.normalize_adc_over_R0()\n",
    "            df_test = g_test.data\n",
    "\n",
    "            # Run multiple accuracy tests\n",
    "            acc = []; error = []\n",
    "            for _ in range(10): \n",
    "                accuracy, abs_error = g.predict_new_data(train_test_split(df_test, test_size=0.2, shuffle=True, random_state=42)[1])\n",
    "                acc.append(accuracy)\n",
    "                error.append(abs_error)\n",
    "\n",
    "            # Compute Min Angle for Accuracy 100%\n",
    "            min_angle_100, all_min_angle_100 = g.get_min_accuracy_100(accuracy_matrix=np.vstack(acc)) or (np.nan, None)\n",
    "            pairwise_min_accuracy[i, j] = np.mean(np.array(all_min_angle_100))\n",
    "\n",
    "            mean_error = np.mean(np.hstack((error)))\n",
    "            pairwise_abs_error[i, j] = mean_error\n",
    "\n",
    "for _, (data, title) in enumerate(zip([pairwise_min_accuracy, pairwise_abs_error], \n",
    "                                      ['Min Angle for 100% Accuracy', 'Mean Absolute Error'])):\n",
    "    f, ax = plt.subplots()\n",
    "    plt.pcolormesh(data, cmap='coolwarm', vmin=np.nanmin(data), vmax=np.nanmax(data))\n",
    "    plt.xticks(np.arange(len(DS_flat))+0.5, xlabel_flat, rotation=90)\n",
    "    plt.xlabel('Test dataset')\n",
    "    plt.yticks(np.arange(len(DS_flat))+0.5, xlabel_flat)\n",
    "    plt.ylabel('Train dataset')\n",
    "    plt.axis('square')\n",
    "    plt.colorbar(label=title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weird...looks like some samples are just bad \"test\" sample datasets, but are ok when testing on their own..? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 8; j = 9 # dataset 1 is a bad test dataset\n",
    "#g = bender_class()\n",
    "#g.load_data(DS_flat[1])\n",
    "#g.normalize_adc_bw_01()\n",
    "#g.plot_data()\n",
    "#g.train_model_test_accuracy(perc_train = 0.99, niter=1)\n",
    "\n",
    "g = bender_class()\n",
    "g.load_data(DS16_datafiles)\n",
    "g.normalize_adc_over_R0()\n",
    "g.plot_data(scatter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
